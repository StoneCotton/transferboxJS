---
description: File operation patterns for the TransferBox file transfer engine
globs: ["src/main/fileTransfer.ts", "src/main/pathProcessor.ts", "src/main/checksumCalculator.ts", "src/main/**/*file*.ts"]
alwaysApply: false
---

# File Operations Guidelines

## Atomic File Transfers

Always use the `.TBPART` temporary file pattern to prevent partial files:

```typescript
import * as fs from 'fs/promises'
import * as path from 'path'

async function transferFile(source: string, dest: string): Promise<void> {
  const tempPath = dest + '.TBPART'
  
  try {
    // 1. Write to temporary file
    await copyFileStreaming(source, tempPath)
    
    // 2. Verify checksum
    const [sourceHash, tempHash] = await Promise.all([
      calculateChecksum(source),
      calculateChecksum(tempPath),
    ])
    
    if (sourceHash !== tempHash) {
      throw new Error('Checksum verification failed')
    }
    
    // 3. Atomic rename (only succeeds if complete)
    await fs.rename(tempPath, dest)
    
  } catch (error) {
    // 4. Clean up temp file on any error
    await fs.unlink(tempPath).catch(() => {})
    throw error
  }
}
```

## Streaming for Large Files

Never load entire files into memory. Use streams with chunked processing:

```typescript
import { createReadStream, createWriteStream } from 'fs'
import { pipeline } from 'stream/promises'

const DEFAULT_BUFFER_SIZE = 4 * 1024 * 1024  // 4MB chunks

async function copyFileStreaming(
  source: string,
  dest: string,
  onProgress?: (bytes: number) => void
): Promise<void> {
  const readStream = createReadStream(source, { highWaterMark: DEFAULT_BUFFER_SIZE })
  const writeStream = createWriteStream(dest)
  
  let transferred = 0
  
  readStream.on('data', (chunk: Buffer) => {
    transferred += chunk.length
    onProgress?.(transferred)
  })
  
  await pipeline(readStream, writeStream)
}
```

## Checksum Verification

Always verify file integrity using XXHash64:

```typescript
import { createReadStream } from 'fs'
import { XXHash64 } from 'xxhash-addon'

async function calculateChecksum(filePath: string): Promise<string> {
  return new Promise((resolve, reject) => {
    const hash = new XXHash64()
    const stream = createReadStream(filePath)
    
    stream.on('data', (chunk: Buffer) => hash.update(chunk))
    stream.on('end', () => resolve(hash.digest('hex')))
    stream.on('error', reject)
  })
}
```

## Safe File Size Arithmetic

Use utilities from `src/main/utils/fileSizeUtils.ts` to prevent overflow:

```typescript
import { safeAdd, safeSum, validateFileSize } from './utils/fileSizeUtils'
import { BYTES_PER_GB, MAX_SAFE_FILE_SIZE } from './constants/fileConstants'

// Safe addition (prevents overflow)
const totalSize = safeAdd(file1.size, file2.size)

// Safe sum for arrays
const batchSize = safeSum(files.map(f => f.size))

// Validate before processing
if (!validateFileSize(size)) {
  throw new Error('File size exceeds safe limits')
}

// Use constants for clarity
const sizeInGB = totalSize / BYTES_PER_GB
```

## Cross-Platform Path Handling

Always use `path` module methods:

```typescript
import * as path from 'path'

// CORRECT: Use path.join for all path construction
const destPath = path.join(destDir, subDir, filename)

// CORRECT: Use path.resolve for absolute paths
const absolutePath = path.resolve(userPath)

// CORRECT: Use path.sep for platform-specific separator
const parts = filePath.split(path.sep)

// WRONG: Never hardcode separators
const badPath = destDir + '/' + filename      // Breaks on Windows
const alsoBad = destDir + '\\' + filename     // Breaks on Unix
```

## Directory Creation

Create directories with recursive option:

```typescript
// Ensure directory exists before writing
await fs.mkdir(path.dirname(destPath), { recursive: true })
await fs.writeFile(destPath, data)
```

## Error Handling

Use the TransferError class for consistent error handling:

```typescript
import { TransferError, TransferErrorType } from './errors/TransferError'

async function readFileWithHandling(filePath: string): Promise<Buffer> {
  try {
    return await fs.readFile(filePath)
  } catch (error) {
    if ((error as NodeJS.ErrnoException).code === 'ENOENT') {
      throw new TransferError(
        TransferErrorType.FileNotFound,
        `File not found: ${path.basename(filePath)}`,
        { path: filePath }
      )
    }
    if ((error as NodeJS.ErrnoException).code === 'EACCES') {
      throw new TransferError(
        TransferErrorType.PermissionDenied,
        `Permission denied: ${path.basename(filePath)}`,
        { path: filePath }
      )
    }
    throw TransferError.wrapError(error, 'File read failed')
  }
}
```

## File Locking

Prevent concurrent access to the same file:

```typescript
const activeTransfers = new Set<string>()

async function transferWithLock(source: string, dest: string): Promise<void> {
  const lockKey = `${source}:${dest}`
  
  if (activeTransfers.has(lockKey)) {
    throw new Error('Transfer already in progress')
  }
  
  activeTransfers.add(lockKey)
  
  try {
    await transferFile(source, dest)
  } finally {
    activeTransfers.delete(lockKey)
  }
}
```

## Progress Reporting

Debounce progress updates to ~100ms intervals:

```typescript
function createProgressReporter(
  onProgress: (progress: TransferProgress) => void,
  debounceMs = 100
): (bytes: number) => void {
  let lastReport = 0
  
  return (bytes: number) => {
    const now = Date.now()
    if (now - lastReport >= debounceMs) {
      onProgress({ bytesTransferred: bytes, timestamp: now })
      lastReport = now
    }
  }
}
```

## Retry Strategy

Use the retry strategy for recoverable errors:

```typescript
import { withRetry } from './utils/retryStrategy'

// Wrap operations that may fail due to device issues
const result = await withRetry(
  () => fs.readFile(sourcePath),
  {
    maxAttempts: 5,
    shouldRetry: (error) => {
      const code = (error as NodeJS.ErrnoException).code
      // Retry on device busy or I/O errors
      return ['EBUSY', 'EIO', 'EAGAIN'].includes(code ?? '')
    }
  }
)
```

## Temporary File Cleanup

Clean up orphaned temp files on startup:

```typescript
const TEMP_FILE_MAX_AGE_MS = 60 * 60 * 1000  // 1 hour

async function cleanupOrphanedTempFiles(directory: string): Promise<void> {
  const files = await fs.readdir(directory)
  const now = Date.now()
  
  for (const file of files) {
    if (!file.endsWith('.TBPART')) continue
    
    const filePath = path.join(directory, file)
    const stats = await fs.stat(filePath)
    
    if (now - stats.mtimeMs > TEMP_FILE_MAX_AGE_MS) {
      await fs.unlink(filePath).catch(() => {})
      logger.info('Cleaned up orphaned temp file:', file)
    }
  }
}
```

## Async File Operations Only

Never use sync methods during transfers:

```typescript
// CORRECT: Async operations
await fs.readFile(path)
await fs.writeFile(path, data)
await fs.stat(path)
await fs.mkdir(dir, { recursive: true })

// WRONG: Sync operations block the main process
fs.readFileSync(path)      // DO NOT USE
fs.writeFileSync(path)     // DO NOT USE
fs.statSync(path)          // DO NOT USE
```

## Conflict Resolution Strategies

Handle file conflicts consistently:

```typescript
type ConflictStrategy = 'skip' | 'overwrite' | 'rename'

async function resolveConflict(
  destPath: string,
  strategy: ConflictStrategy
): Promise<string | null> {
  const exists = await fs.access(destPath).then(() => true).catch(() => false)
  
  if (!exists) return destPath
  
  switch (strategy) {
    case 'skip':
      return null  // Skip this file
      
    case 'overwrite':
      return destPath  // Use same path, will overwrite
      
    case 'rename':
      return generateUniquePath(destPath)
  }
}

function generateUniquePath(originalPath: string): string {
  const { dir, name, ext } = path.parse(originalPath)
  let counter = 1
  let newPath: string
  
  do {
    newPath = path.join(dir, `${name} (${counter})${ext}`)
    counter++
  } while (fs.existsSync(newPath))  // Only sync method allowed here (startup)
  
  return newPath
}
```
